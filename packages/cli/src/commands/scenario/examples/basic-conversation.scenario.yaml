name: "Basic Multi-Turn Conversation Test"
description: "Tests basic multi-turn conversation capabilities with user simulation"

plugins:
  - name: '@elizaos/plugin-bootstrap'
    enabled: true
  - name: '@elizaos/plugin-sql'
    enabled: true
  - name: '@elizaos/plugin-openai'
    enabled: true

environment:
  type: local

run:
  - name: "Simple customer support conversation"
    input: "Hi, I need help with something regarding billing"
    
    conversation:
      max_turns: 2
      user_simulator:
        persona: "polite customer with a billing question"
        objective: "find out why charged twice this month"
        temperature: 0.6
        style: "friendly and patient"
        constraints:
          - "Be polite and cooperative"
          - "Provide details when asked"
          - "Express gratitude for help"
      
      termination_conditions:
        - type: "user_expresses_satisfaction"
          keywords: ["thank you", "that helps", "resolved", "great", "perfect"]
        - type: "agent_provides_solution"
          keywords: ["follow these steps", "complete solution", "problem is solved", "issue resolved"]
      
      turn_evaluations:
        - type: "llm_judge"
          prompt: "Did the agent respond helpfully and professionally?"
          expected: "yes"
      
      final_evaluations:
        - type: "llm_judge"
          prompt: "Did the agent successfully help resolve the billing issue?"
          expected: "yes"
          capabilities:
            - "Understood the customer's billing concern"
            - "Asked appropriate follow-up questions"
            - "Provided helpful information or solutions"
            - "Maintained a professional and helpful tone"

    # Traditional single evaluations still supported for backward compatibility
    evaluations:
      - type: "string_contains"
        value: "help"

judgment:
  strategy: all_pass
